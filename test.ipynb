{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Trains: Iron Horses of Industry\n",
      "Segments: [\n",
      "    {\n",
      "        \"start_time\": 0,\n",
      "        \"end_time\": 6,\n",
      "        \"text_1\": \"For centuries, trains have connected\",\n",
      "        \"visual_prompt_1\": \"DALL-E 2: A vintage steam locomotive pulling a long line of passenger cars through a scenic mountain pass.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 7,\n",
      "        \"end_time\": 12,\n",
      "        \"text_2\": \"people and goods across vast distances,\",\n",
      "        \"visual_prompt_2\": \"DALL-E 2: A modern high-speed bullet train speeding through a futuristic cityscape.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 13,\n",
      "        \"end_time\": 18,\n",
      "        \"text_3\": \"shaping the world as we know it.\",\n",
      "        \"visual_prompt_3\": \"DALL-E 2: A map of the world highlighting major railway networks, showcasing their global reach.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 19,\n",
      "        \"end_time\": 24,\n",
      "        \"text_4\": \"From the early steam engines of the\",\n",
      "        \"visual_prompt_4\": \"DALL-E 2: An illustration of George Stephenson's Rocket, one of the first successful steam locomotives.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 25,\n",
      "        \"end_time\": 30,\n",
      "        \"text_5\": \"Industrial Revolution to today's\",\n",
      "        \"visual_prompt_5\": \"DALL-E 2: A photograph of a maglev train levitating above its tracks, showcasing modern advancements.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 31,\n",
      "        \"end_time\": 36,\n",
      "        \"text_6\": \"high-speed marvels, trains have\",\n",
      "        \"visual_prompt_6\": \"DALL-E 2: A time-lapse of a train journey, transitioning from historical steam engines to modern high-speed trains.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 37,\n",
      "        \"end_time\": 42,\n",
      "        \"text_7\": \"revolutionized transportation and\",\n",
      "        \"visual_prompt_7\": \"DALL-E 2: A bustling train station with people boarding and departing trains, highlighting the role of trains in daily life.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 43,\n",
      "        \"end_time\": 48,\n",
      "        \"text_8\": \"trade on a global scale.\",\n",
      "        \"visual_prompt_8\": \"DALL-E 2: A container ship being loaded with cargo containers transported by trains, showcasing the interconnectedness of global trade.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 49,\n",
      "        \"end_time\": 54,\n",
      "        \"text_9\": \"Join us as we explore the fascinating\",\n",
      "        \"visual_prompt_9\": \"DALL-E 2: A montage of various train-related images, including historical photos, modern trains, and scenic railway journeys.\"\n",
      "    }\n",
      "]\n",
      "['https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-nWyuxEcZpG09A3JEHNNODYVU.png?st=2024-05-03T15%3A01%3A55Z&se=2024-05-03T17%3A01%3A55Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A39%3A10Z&ske=2024-05-03T23%3A39%3A10Z&sks=b&skv=2021-08-06&sig=RWWUav0/J1tozMXr21sR8LfVR0TEr1hnYcSf%2BIufanQ%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-CJpmZHyqAdet8V8qtK0k8vh3.png?st=2024-05-03T15%3A02%3A06Z&se=2024-05-03T17%3A02%3A06Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A34%3A02Z&ske=2024-05-03T23%3A34%3A02Z&sks=b&skv=2021-08-06&sig=rqg8UNgSLyAXP4A4EP7st61kxcKoPRr16JseHp1qkx0%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-sx2hRoT5fn1zMLxtLrSN4v6D.png?st=2024-05-03T15%3A02%3A15Z&se=2024-05-03T17%3A02%3A15Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A32%3A26Z&ske=2024-05-03T23%3A32%3A26Z&sks=b&skv=2021-08-06&sig=NstftVnltTnWqY5bd5SVSDVq6zQY5W9Da81zhbgrm78%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-QWidjpkSqlAnKWDpQABylHlh.png?st=2024-05-03T15%3A02%3A25Z&se=2024-05-03T17%3A02%3A25Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A35%3A08Z&ske=2024-05-03T23%3A35%3A08Z&sks=b&skv=2021-08-06&sig=9B3VoUKhG19Gzxkcg8ttH5m%2Bux77AWluPen3LpZDF14%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-vDQIjJQW2RG2KdE6Bupu2Mfu.png?st=2024-05-03T15%3A02%3A35Z&se=2024-05-03T17%3A02%3A35Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A45%3A07Z&ske=2024-05-03T23%3A45%3A07Z&sks=b&skv=2021-08-06&sig=qqS59BULiRIyb97ijbwwbgUrjdBkWEHzh%2BOmUYaRyUM%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-kYvgZNHL6z9X4JBtkTbt2WHt.png?st=2024-05-03T15%3A02%3A46Z&se=2024-05-03T17%3A02%3A46Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-03T13%3A43%3A01Z&ske=2024-05-04T13%3A43%3A01Z&sks=b&skv=2021-08-06&sig=DumX8RHTKDqs59WBYCrw87ZkhtCt8zL1ytHX6utvtR8%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-ZF96DwHgN6bGvdntidMSVllC.png?st=2024-05-03T15%3A02%3A56Z&se=2024-05-03T17%3A02%3A56Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A37%3A21Z&ske=2024-05-03T23%3A37%3A21Z&sks=b&skv=2021-08-06&sig=MpNPQkkEqpWRX1dTaue8LX9Th0ToZQtIOgf/Cr%2BWTVo%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-8EqdF5s6TwIg9jP3o5g6pHhu.png?st=2024-05-03T15%3A03%3A06Z&se=2024-05-03T17%3A03%3A06Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A45%3A15Z&ske=2024-05-03T23%3A45%3A15Z&sks=b&skv=2021-08-06&sig=BgrKYwYt9dH5NljSwtDj9M8HXJjeibNNvbI8Uz8eZxY%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-WxDzTMqAYyfoTcvuQXrJMRD8.png?st=2024-05-03T15%3A03%3A16Z&se=2024-05-03T17%3A03%3A16Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A28%3A55Z&ske=2024-05-03T23%3A28%3A55Z&sks=b&skv=2021-08-06&sig=4buTIjKPawqfwLGJBlgsBZFAV9op90j3MIsnOpJQ%2Byw%3D']\n",
      "2024-05-03_21-33-16\n",
      "Downloaded and saved: 2024-05-03_21-33-16/image_1.png\n"
     ]
    }
   ],
   "source": [
    "from director import script\n",
    "from image_generation import image_generator\n",
    "from audio_generation import generate_audio_clips\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import subprocess  # For running ffmpeg command\n",
    "from datetime import datetime\n",
    "from moviepy.editor import TextClip, CompositeVideoClip, ImageClip, concatenate_videoclips\n",
    "\n",
    "url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyC8tc7m4TkAmfOx9cu_bckCc62ZgVDzSBQ\"\n",
    "\n",
    "# Prompting the user for input\n",
    "context = input(\"Enter the context along with the Item name: \")\n",
    "\n",
    "\n",
    "# this would be some pre research.\n",
    "reqdata = {\n",
    "    \"item\": f\"{context}\",\n",
    "    \"context\": \"Provide some context or specific detail you want to focus on\",\n",
    "    \"origin\": \"Discuss the geographic and historical origin of the item\",\n",
    "    \"inventor\": \"Identify the inventor(s) or creator(s) if applicable\",\n",
    "    \"initial_adoption\": \"Describe how and where it was first adopted or popularized\",\n",
    "    \"manufacturing_process\": \"Explain how the item is made or produced\",\n",
    "    \"cultural_impact\": \"Analyze the cultural significance or impact of the item\",\n",
    "    \"technological_influence\": \"Discuss any technological influence or advancements due to the item\",\n",
    "    \"economic_importance\": \"Reflect on the economic relevance of the item, including market impact\",\n",
    "    \"environmental_impact\": \"Address any environmental considerations or impacts\",\n",
    "    \"legal_aspects\": \"Mention any notable legal battles or patent issues related to the item\",\n",
    "    \"modern_day_usage\": \"Describe current uses and applications\",\n",
    "    \"evolution_over_time\": \"Trace the evolution or changes in design, function, or popularity over time\",\n",
    "    \"future_prospects\": \"Speculate on future developments or directions for the item\"\n",
    "}\n",
    "\n",
    "# Predefined JSON structure\n",
    "expected_format = {\n",
    "    \"title\": \"suggest a title for the video based on the item\",\n",
    "    \"segments\": [\n",
    "        {\n",
    "            \"start_time\": 0,\n",
    "            \"end_time\": 6,\n",
    "            \"text_1\": \"13 word only\",\n",
    "            \"visual_prompt_1\": \"verbose\"\n",
    "        },\n",
    "        {\n",
    "            \"start_time\": 7,\n",
    "            \"end_time\": 12,\n",
    "            \"text_2\": \"13 word only\",\n",
    "            \"visual_prompt_2\":  \"verbose\"\n",
    "        },\n",
    "        {\n",
    "            \"start_time\": \"n\",\n",
    "            \"end_time\": \"12\",\n",
    "            \"text_2\": \"13 word only\",\n",
    "            \"visual_prompt_2\":  \"verbose\"\n",
    "        },\n",
    "        {\n",
    "            \"start_time\": 49,\n",
    "            \"end_time\": 54,\n",
    "            \"text_9\": \"13 word only\",\n",
    "            \"visual_prompt_9\":  \"verbose\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "modelbrief = {\n",
    "    \"model_name\": \"DALL-E 2\",\n",
    "    \"description\": \"An advanced AI image generation model from OpenAI that creates detailed and realistic images from textual descriptions. It is more of an image engineer than an artist.\",\n",
    "    \"strengths\": [\n",
    "        \"Produces high-quality, photorealistic images, often surpassing the detail and style requested.\",\n",
    "        \"Capable of complex image generation, combining elements creatively in new ways which feel almost like human intelligence.\",\n",
    "    ],\n",
    "    \"weaknesses\": [\n",
    "        \"Complex or abstract concepts can sometimes challenge the model, leading to unpredictable or less accurate renditions.\",\n",
    "        \"While it has safety protocols to prevent generating inappropriate content, these can also limit the scope of creative outputs in sensitive areas.\",\n",
    "        \"absolutely horrible at generating graphical data or technical data or even repeating any kind of text\",\n",
    "    ],\n",
    "    \"limitations\": [\n",
    "        \"Not suitable for creating accurate maps, graphs, or other specific informational graphics.\",\n",
    "        \"May not always adhere to strict historical or factual accuracy without highly detailed prompts.\",\n",
    "        \"Content generation is restricted to avoid generating harmful or misleading images.\",\n",
    "        \"The need for careful prompt design to avoid unwanted or unexpected elements in the generated images.\"\n",
    "    ]\n",
    "}\n",
    "modelbrief2 = {\n",
    "    \"model_name\": \"DALL-E-3\",\n",
    "    \"description\": \"An advanced AI image generation model from OpenAI that creates highly detailed and realistic images from textual descriptions. It is more of an image engineer than an artist.\",\n",
    "    \"strengths\": [\n",
    "        \"very good at capturing details.\",\n",
    "        \"be very specific and verbose it can also stick to themes and story lines so you can keep the visual text being returned verbose\",\n",
    "    ],\n",
    "    \"weaknesses\": [\n",
    "        \"Complex or abstract concepts can sometimes challenge the model, leading to unpredictable or less accurate renditions.\",\n",
    "        \"While it has safety protocols to prevent generating inappropriate content, these can also limit the scope of creative outputs in sensitive areas.\",\n",
    "        \"absolutely horrible at generating graphical data or technical data or even repeating any kind of text\",\n",
    "    ],\n",
    "    \"limitations\": [\n",
    "        \"Not suitable for generating explicit or potentially harmful content due to ethical guidelines and restrictions.\",\n",
    "        \"May not always adhere to strict historical or factual accuracy without highly detailed prompts.\",\n",
    "        \"The quality of results can vary based on the specificity and clarity of the prompts provided so\"\n",
    "    ]\n",
    "}\n",
    "modelbrief3 = {\n",
    "    \"model_name\": \"gTTS\",\n",
    "    \"description\": \"Google Text-to-Speech (gTTS) is a Python library and CLI tool that interfaces with Google's Text-to-Speech API. It converts text into natural-sounding spoken audio. gTTS supports multiple languages and is commonly used in applications that require spoken feedback or audio content.\",\n",
    "    \"strengths\": [\n",
    "        \"Produces clear and natural-sounding voice outputs, enhancing user engagement and understanding.\"\n",
    "    ],\n",
    "    \"weaknesses\": [\n",
    "        \"slow at reciting so produce only about 13 words per 5 seconds\",\n",
    "        \"Limited control over voice modulation and emotional intonation compared to more advanced speech synthesis tools.\",\n",
    "    ],\n",
    "    \"adaptations\": [\n",
    "        \"Adapt the length of text to ensure compatibility with the audio duration specified in video segments.\",\n",
    "        \"Generate succinct and clear audio segments that align with the visual content's timing and pacing.\"\n",
    "    ],\n",
    "    \"limitations\": [\n",
    "        \"Lacks advanced features like speech emotion or different speaking styles, which are available in more specialized TTS systems.\",\n",
    "        \"While it supports many languages, the quality of speech generation can vary between them.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "system_instructions = [\n",
    "        \"Output strictly valid JSON only. Ensure the text fields are concise to fit within the designated timestamps for audio. the timestampse are in seconds\",\n",
    "        \"Maintain key integrity; ensure all fields are accurately populated.\",\n",
    "        \"Ensure a high correlation between visual prompts and the narrative text to enhance content relevance and viewer engagement.\",\n",
    "        \"STRICTLY output only 13 words per 5 seconds for text_n field\",\n",
    "        \"follow the models strengths and weknesses carefully\",\n",
    "        \"MAKE SURE THE VISUAL PROPT IS VERBOSE in visual_prompt_n\"\n",
    "    ]\n",
    "# Joining the instructions into a single string with each instruction on a new line for clarity\n",
    "system_prompt = \"Please follow these instructions:\\n\" + \"\\n\".join(system_instructions)\n",
    "# Constructing user prompt\n",
    "userprompt = f\"strict instructions: {context}. Here's the expected_format: {json.dumps(expected_format)}. try to incorporate along the lines of : {reqdata}. visual_prompt_n using the model: {modelbrief} text_n using the model: {modelbrief3}.\"\n",
    "\n",
    "response = script(system_prompt, userprompt, url)\n",
    "content = json.dumps(response)\n",
    "#print (content)\n",
    "\n",
    "response_json = json.loads(response)# Store the title in a variable\n",
    "title = response_json['title']\n",
    "# Store the segments as a list\n",
    "segments = response_json['segments']\n",
    "\n",
    "# Output the stored data\n",
    "print(\"Title:\", title)\n",
    "print(\"Segments:\", json.dumps(segments, indent=4))\n",
    "\n",
    "visual_prompts = [segment[f'visual_prompt_{i+1}'] for i, segment in enumerate(segments)]\n",
    "\n",
    "# Generating images\n",
    "images_urls = image_generator(visual_prompts)\n",
    "\n",
    "print(images_urls)\n",
    "\n",
    "# Creating a directory with the current timestamp\n",
    "dir_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "print(dir_name)\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "#download urls\n",
    "for idx, url in enumerate(images_urls):\n",
    "    response = requests.get(url)\n",
    "    file_path = os.path.join(dir_name, f\"image_{idx+1}.png\")\n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded and saved: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download image from {url}\")\n",
    "\n",
    "# Creating video clips from images\n",
    "def create_video_clip(image_paths, fixed_duration=6):\n",
    "    clips = [ImageClip(image).set_duration(fixed_duration) for image in image_paths]\n",
    "    return concatenate_videoclips(clips, method=\"compose\")\n",
    "\n",
    "\n",
    "def add_subtitles(video, segments):\n",
    "    composite_clips = [video]  # Start with the main video clip\n",
    "    for idx, segment in enumerate(segments):\n",
    "        text = segment.get(f'text_{idx+1}', '')  # Extract text\n",
    "        start_time = segment.get('start_time', 0)\n",
    "        end_time = segment.get('end_time', start_time + 5)  # Default duration 5 seconds\n",
    "\n",
    "        # Creating the subtitle clip\n",
    "        subtitle_clip = TextClip(\n",
    "            text, fontsize=60, color='white', font='Impact',\n",
    "            size=(video.size[0] * 0.8, None),  # Set width to 80% of the video width\n",
    "            method='caption', align='South', stroke_color='orange2', stroke_width=3.5,\n",
    "        )\n",
    "\n",
    "        # Set subtitle clip start and duration times\n",
    "        subtitle_clip = subtitle_clip.set_start(start_time).set_duration(end_time - start_time)\n",
    "\n",
    "        # Set position to center and make sure it maintains 10% margin\n",
    "        subtitle_clip = subtitle_clip.set_position(('right', 'bottom')) #horizontal,vertical\n",
    "\n",
    "        composite_clips.append(subtitle_clip)\n",
    "        print(\"subtitles added\")\n",
    "    \n",
    "    # Return a composite clip that includes the video and subtitles\n",
    "    return CompositeVideoClip(composite_clips)\n",
    "\n",
    "# Creating final video with ffmpeg\n",
    "def create_final_video(composite_video, audio, output_path):\n",
    "    temp_video_path = output_path.replace('.mp4', '_temp.mp4')\n",
    "    composite_video.write_videofile(temp_video_path, codec=\"libx264\", fps=24)\n",
    "    audio.write_audiofile(output_path.replace('.mp4', '_temp_audio.mp3'))\n",
    "    ffmpeg_command = [\n",
    "        'ffmpeg',\n",
    "        '-i', temp_video_path,\n",
    "        '-i', output_path.replace('.mp4', '_temp_audio.mp3'),\n",
    "        '-c:v', 'copy',\n",
    "        '-c:a', 'aac',\n",
    "        '-strict', 'experimental',\n",
    "        output_path\n",
    "    ]\n",
    "    subprocess.run(ffmpeg_command, check=True)\n",
    "\n",
    "\n",
    "temp_audio_dir = os.path.join(dir_name, 'temp_audio')\n",
    "os.makedirs(temp_audio_dir, exist_ok=True)\n",
    "\n",
    "image_files = [os.path.join(dir_name, f\"image_{i+1}.png\") for i in range(len(images_urls))]\n",
    "image_durations = [(item['end_time'] - item['start_time']) for item in segments]\n",
    "\n",
    "initial_video = create_video_clip(image_files)\n",
    "subtitled_video = add_subtitles(initial_video, segments)\n",
    "audio_clips = generate_audio_clips(segments, temp_audio_dir)\n",
    "final_video_path = os.path.join(dir_name, f\"{title}_final.mp4\")\n",
    "create_final_video(subtitled_video, audio_clips, final_video_path)\n",
    "\n",
    "print(f\"Final video with subtitles and audio saved to {final_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video 2024-05-01_23-50-29/Into the Deep: A History of Submarines_final_temp.mp4.\n",
      "Moviepy - Writing video 2024-05-01_23-50-29/Into the Deep: A History of Submarines_final_temp.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready 2024-05-01_23-50-29/Into the Deep: A History of Submarines_final_temp.mp4\n",
      "MoviePy - Writing audio in 2024-05-01_23-50-29/Into the Deep: A History of Submarines_final_temp_audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0 Copyright (c) 2000-2024 the FFmpeg developers     \n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.0 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '2024-05-01_23-50-29/Into the Deep: A History of Submarines_final_temp.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:00:48.00, start: 0.000000, bitrate: 389 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 1024x1024, 386 kb/s, 24 fps, 24 tbr, 12288 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 libx264\n",
      "Input #1, mp3, from '2024-05-01_23-50-29/Into the Deep: A History of Submarines_final_temp_audio.mp3':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:00:51.91, start: 0.025057, bitrate: 128 kb/s\n",
      "  Stream #1:0: Audio: mp3 (mp3float), 44100 Hz, stereo, fltp, 128 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (mp3 (mp3float) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to '2024-05-01_23-50-29/Into the Deep: A History of Submarines_final.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf61.1.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 1024x1024, q=2-31, 386 kb/s, 24 fps, 24 tbr, 12288 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 libx264\n",
      "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 aac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "size=    2048KiB time=00:00:31.76 bitrate= 528.2kbits/s speed=62.9x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final video with subtitles and audio saved to 2024-05-01_23-50-29/Into the Deep: A History of Submarines_final.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/mp4 @ 0x13ce44460] video:2267KiB audio:808KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 1.239631%\n",
      "size=    3114KiB time=00:00:47.91 bitrate= 532.4kbits/s speed=58.2x    \n",
      "[aac @ 0x13ce47130] Qavg: 1301.893\n"
     ]
    }
   ],
   "source": [
    "audio_clips = generate_audio_clips(segments, temp_audio_dir)\n",
    "final_video_path = os.path.join(dir_name, f\"{title}_final.mp4\")\n",
    "create_final_video(subtitled_video, audio_clips, final_video_path)\n",
    "\n",
    "print(f\"Final video with subtitles and audio saved to {final_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Boat Chronicles: A Journey Through Maritime History\n",
      "Segments: [\n",
      "    {\n",
      "        \"start_time\": 0,\n",
      "        \"end_time\": 6,\n",
      "        \"text_1\": \"From Rafts to Ocean Liners: Tracing the Evolution of Maritime Travel\",\n",
      "        \"visual_prompt_1\": \"In the dawn of civilization, humanity crafted rafts from primitive materials, venturing into the unknown waters of rivers and lakes. These humble vessels, fashioned from woven reeds and animal hides, symbolize our earliest aspirations for exploration and discovery.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 7,\n",
      "        \"end_time\": 12,\n",
      "        \"text_2\": \"Explorers and Empires: Navigating the High Seas of Medieval Times\",\n",
      "        \"visual_prompt_2\": \"Amidst the tumultuous waves of medieval seas, sturdy galleys and longships carried intrepid explorers to distant shores. These wooden behemoths, powered by the strength of oarsmen and the mercy of the wind, braved storms and conquered new horizons.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 13,\n",
      "        \"end_time\": 18,\n",
      "        \"text_3\": \"Trade Winds and Tall Ships: Unveiling the Renaissance Maritime Revolution\",\n",
      "        \"visual_prompt_3\": \"As the Renaissance dawned, majestic caravels and galleons unfurled their billowing sails, riding the trade winds to exotic lands. These towering vessels, adorned with intricate carvings and colorful flags, heralded a new age of maritime exploration and commerce.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 19,\n",
      "        \"end_time\": 24,\n",
      "        \"text_4\": \"Steam and Steel: Embracing Industrial Maritime Innovation\",\n",
      "        \"visual_prompt_4\": \"With the advent of the industrial revolution, ironclad steamships plied the world's oceans, transforming travel and trade. These mighty vessels, propelled by the power of steam and fueled by coal, ushered in an era of global connectivity and economic expansion.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 25,\n",
      "        \"end_time\": 30,\n",
      "        \"text_5\": \"Modern Marvels: Experiencing Luxury and Adventure on Contemporary Yachts\",\n",
      "        \"visual_prompt_5\": \"In the modern era, sleek yachts and cruise liners epitomize luxury and adventure on the high seas. These floating palaces, equipped with state-of-the-art amenities and cutting-edge technology, offer travelers unparalleled comfort and style as they traverse the world's oceans.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 31,\n",
      "        \"end_time\": 36,\n",
      "        \"text_6\": \"Exploring the Unknown: Delving into Oceanographic Expeditions\",\n",
      "        \"visual_prompt_6\": \"Beneath the waves, research vessels equipped with advanced sonar and submersibles delve into the mysteries of the deep. These scientific marvels, manned by intrepid explorers and equipped with state-of-the-art equipment, unlock the secrets of the ocean, from uncharted depths to thriving ecosystems.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 37,\n",
      "        \"end_time\": 42,\n",
      "        \"text_7\": \"Sustainable Solutions: Embracing Eco-Friendly Practices in Boating\",\n",
      "        \"visual_prompt_7\": \"Amid growing environmental concerns, eco-friendly boats harness renewable energy and sustainable materials to navigate the world's waterways. From solar-powered catamarans to wind-propelled schooners, these green vessels pave the way towards a cleaner, greener future for maritime travel.\"\n",
      "    },\n",
      "    {\n",
      "        \"start_time\": 43,\n",
      "        \"end_time\": 48,\n",
      "        \"text_8\": \"Future Frontiers: Envisioning Innovations in Autonomous Shipping\",\n",
      "        \"visual_prompt_8\": \"In the era of automation, autonomous ships equipped with AI and sensors navigate the seas with unparalleled precision and efficiency. These unmanned vessels, guided by artificial intelligence and powered by renewable energy, herald a new chapter in maritime innovation and sustainability.\"\n",
      "    }\n",
      "]\n",
      "['https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-cjmIcyVnbr1AwsaM2kw832l3.png?st=2024-05-03T18%3A15%3A39Z&se=2024-05-03T20%3A15%3A39Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A32%3A19Z&ske=2024-05-03T23%3A32%3A19Z&sks=b&skv=2021-08-06&sig=p1SuIn922px18T5odw4i0Ei64g2lXzmrnKXRh%2BTFisw%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-G9HU6NRUPwthwDns5VZeszyD.png?st=2024-05-03T18%3A15%3A50Z&se=2024-05-03T20%3A15%3A50Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A44%3A15Z&ske=2024-05-03T23%3A44%3A15Z&sks=b&skv=2021-08-06&sig=JS%2BANZVULucVQ2uDINZ1zYqXKlaljxVcXG6NV5KIfLk%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-G9x9Y2RXjltSiRFOwzn6JDVC.png?st=2024-05-03T18%3A16%3A01Z&se=2024-05-03T20%3A16%3A01Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-03T00%3A07%3A55Z&ske=2024-05-04T00%3A07%3A55Z&sks=b&skv=2021-08-06&sig=l0ZaVaer8AEt6JooXa1FtycrbHYRWnEVFm4HK1sI8TU%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-GcVx50U0DjhIMFml0fI1crkS.png?st=2024-05-03T18%3A16%3A11Z&se=2024-05-03T20%3A16%3A11Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-03T00%3A05%3A44Z&ske=2024-05-04T00%3A05%3A44Z&sks=b&skv=2021-08-06&sig=EHJLFE3w4Vo4thewZv1DJLKJd/45elyxfuNfzc/yoYc%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-E1Qk1DiCH7xKqdA1j8TJESX8.png?st=2024-05-03T18%3A16%3A21Z&se=2024-05-03T20%3A16%3A21Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A36%3A41Z&ske=2024-05-03T23%3A36%3A41Z&sks=b&skv=2021-08-06&sig=p3RYPBDw9LEnNaX6i3Q/p3wwYi9mgmEedeMluFPoOo0%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-3NktjXLriKhcIiMp91yKINby.png?st=2024-05-03T18%3A16%3A32Z&se=2024-05-03T20%3A16%3A32Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A52%3A33Z&ske=2024-05-03T23%3A52%3A33Z&sks=b&skv=2021-08-06&sig=qxHazsRZgA0EGKYwgr%2BJxT5NxiRriB3/MS%2BcHdBO3%2B4%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-jliTVNCtrH3DklILtt9Suo3k.png?st=2024-05-03T18%3A16%3A44Z&se=2024-05-03T20%3A16%3A44Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A31%3A56Z&ske=2024-05-03T23%3A31%3A56Z&sks=b&skv=2021-08-06&sig=IQsE4JsXMD4swnGiQFwzlnOn5X7Wrbqi873bmDELYFs%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-D7OT8XFExi5i4nqrKyvVqPcA/user-TtI17rNcNSYj17zU9kgnKBmZ/img-b9cnAXDMTgf6vtmnBieE0UtK.png?st=2024-05-03T18%3A16%3A54Z&se=2024-05-03T20%3A16%3A54Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-02T23%3A33%3A06Z&ske=2024-05-03T23%3A33%3A06Z&sks=b&skv=2021-08-06&sig=RV6r9zrT4A5ktJ81aeTXSVIFFxlz0RnkwMiXkcgTjtU%3D']\n",
      "2024-05-04_00-46-54\n",
      "Downloaded and saved: 2024-05-04_00-46-54/image_1.png\n",
      "Downloaded and saved: 2024-05-04_00-46-54/image_2.png\n",
      "Downloaded and saved: 2024-05-04_00-46-54/image_3.png\n"
     ]
    },
    {
     "ename": "ChunkedEncodingError",
     "evalue": "('Connection broken: IncompleteRead(1211847 bytes read, 1936134 more expected)', IncompleteRead(1211847 bytes read, 1936134 more expected))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/response.py:737\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 737\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/response.py:883\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    874\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menforce_content_length\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# raised during streaming, so all calls with incorrect\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Content-Length are caught.\u001b[39;00m\n\u001b[0;32m--> 883\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_bytes_read, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining)\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read1 \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    885\u001b[0m     (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m    886\u001b[0m ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;66;03m# `http.client.HTTPResponse`, so we close it here.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# See https://github.com/python/cpython/issues/113199\u001b[39;00m\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(1211847 bytes read, 1936134 more expected)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/response.py:1043\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1043\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/response.py:963\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m<\u001b[39m amt \u001b[38;5;129;01mand\u001b[39;00m data:\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;66;03m# TODO make sure to initially read enough data to get past the headers\u001b[39;00m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# For example, the GZ file header takes 10 bytes, we don't want to read\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;66;03m# it one byte at a time\u001b[39;00m\n\u001b[0;32m--> 963\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m     decoded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(data, decode_content, flush_decoder)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/response.py:861\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 861\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_error_catcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfp_closed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/response.py:761\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m         arg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection broken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 761\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProtocolError(arg, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (HTTPException, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(1211847 bytes read, 1936134 more expected)', IncompleteRead(1211847 bytes read, 1936134 more expected))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#download urls\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images_urls):\n\u001b[0;32m---> 91\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_name, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/models.py:818\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContentDecodingError(e)\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(1211847 bytes read, 1936134 more expected)', IncompleteRead(1211847 bytes read, 1936134 more expected))"
     ]
    }
   ],
   "source": [
    "from director import script\n",
    "from image_generation import image_generator\n",
    "from audio_generation import generate_audio_clips\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import subprocess  # For running ffmpeg command\n",
    "from datetime import datetime\n",
    "from moviepy.editor import TextClip, CompositeVideoClip, ImageClip, concatenate_videoclips\n",
    "\n",
    "response = \"\"\"{\n",
    "    \"title\": \"Boat Chronicles: A Journey Through Maritime History\",\n",
    "    \"segments\": [\n",
    "        {\n",
    "            \"start_time\": 0,\n",
    "            \"end_time\": 6,\n",
    "            \"text_1\": \"From Rafts to Ocean Liners: Tracing the Evolution of Maritime Travel\",\n",
    "            \"visual_prompt_1\": \"In the dawn of civilization, humanity crafted rafts from primitive materials, venturing into the unknown waters of rivers and lakes. These humble vessels, fashioned from woven reeds and animal hides, symbolize our earliest aspirations for exploration and discovery.\"\n",
    "        },\n",
    "        {\n",
    "            \"start_time\": 7,\n",
    "            \"end_time\": 12,\n",
    "            \"text_2\": \"Explorers and Empires: Navigating the High Seas of Medieval Times\",\n",
    "            \"visual_prompt_2\":  \"Amidst the tumultuous waves of medieval seas, sturdy galleys and longships carried intrepid explorers to distant shores. These wooden behemoths, powered by the strength of oarsmen and the mercy of the wind, braved storms and conquered new horizons.\"\n",
    "        },\n",
    "        {\n",
    "            \"start_time\": 13,\n",
    "            \"end_time\": 18,\n",
    "            \"text_3\": \"Trade Winds and Tall Ships: Unveiling the Renaissance Maritime Revolution\",\n",
    "            \"visual_prompt_3\":  \"As the Renaissance dawned, majestic caravels and galleons unfurled their billowing sails, riding the trade winds to exotic lands. These towering vessels, adorned with intricate carvings and colorful flags, heralded a new age of maritime exploration and commerce.\"\n",
    "        },\n",
    "        {\n",
    "            \"start_time\": 19,\n",
    "            \"end_time\": 24,\n",
    "            \"text_4\": \"Steam and Steel: Embracing Industrial Maritime Innovation\",\n",
    "            \"visual_prompt_4\":  \"With the advent of the industrial revolution, ironclad steamships plied the world's oceans, transforming travel and trade. These mighty vessels, propelled by the power of steam and fueled by coal, ushered in an era of global connectivity and economic expansion.\"\n",
    "        },\n",
    "        {\n",
    "            \"start_time\": 25,\n",
    "            \"end_time\": 30,\n",
    "            \"text_5\": \"Modern Marvels: Experiencing Luxury and Adventure on Contemporary Yachts\",\n",
    "            \"visual_prompt_5\":  \"In the modern era, sleek yachts and cruise liners epitomize luxury and adventure on the high seas. These floating palaces, equipped with state-of-the-art amenities and cutting-edge technology, offer travelers unparalleled comfort and style as they traverse the world's oceans.\"\n",
    "        },\n",
    "        {\n",
    "            \"start_time\": 31,\n",
    "            \"end_time\": 36,\n",
    "            \"text_6\": \"Exploring the Unknown: Delving into Oceanographic Expeditions\",\n",
    "            \"visual_prompt_6\":  \"Beneath the waves, research vessels equipped with advanced sonar and submersibles delve into the mysteries of the deep. These scientific marvels, manned by intrepid explorers and equipped with state-of-the-art equipment, unlock the secrets of the ocean, from uncharted depths to thriving ecosystems.\"\n",
    "        },\n",
    "        {\n",
    "            \"start_time\": 37,\n",
    "            \"end_time\": 42,\n",
    "            \"text_7\": \"Sustainable Solutions: Embracing Eco-Friendly Practices in Boating\",\n",
    "            \"visual_prompt_7\":  \"Amid growing environmental concerns, eco-friendly boats harness renewable energy and sustainable materials to navigate the world's waterways. From solar-powered catamarans to wind-propelled schooners, these green vessels pave the way towards a cleaner, greener future for maritime travel.\"\n",
    "        },\n",
    "        {\n",
    "            \"start_time\": 43,\n",
    "            \"end_time\": 48,\n",
    "            \"text_8\": \"Future Frontiers: Envisioning Innovations in Autonomous Shipping\",\n",
    "            \"visual_prompt_8\":  \"In the era of automation, autonomous ships equipped with AI and sensors navigate the seas with unparalleled precision and efficiency. These unmanned vessels, guided by artificial intelligence and powered by renewable energy, herald a new chapter in maritime innovation and sustainability.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "content = json.dumps(response)\n",
    "#print (content)\n",
    "\n",
    "response_json = json.loads(response)# Store the title in a variable\n",
    "title = response_json['title']\n",
    "# Store the segments as a list\n",
    "segments = response_json['segments']\n",
    "\n",
    "# Output the stored data\n",
    "print(\"Title:\", title)\n",
    "print(\"Segments:\", json.dumps(segments, indent=4))\n",
    "\n",
    "visual_prompts = [segment[f'visual_prompt_{i+1}'] for i, segment in enumerate(segments)]\n",
    "\n",
    "# Generating images\n",
    "images_urls = image_generator(visual_prompts)\n",
    "\n",
    "print(images_urls)\n",
    "\n",
    "# Creating a directory with the current timestamp\n",
    "dir_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "print(dir_name)\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "#download urls\n",
    "for idx, url in enumerate(images_urls):\n",
    "    response = requests.get(url)\n",
    "    file_path = os.path.join(dir_name, f\"image_{idx+1}.png\")\n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded and saved: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download image from {url}\")\n",
    "\n",
    "# Creating video clips from images\n",
    "def create_video_clip(image_paths, fixed_duration=6):\n",
    "    clips = [ImageClip(image).set_duration(fixed_duration) for image in image_paths]\n",
    "    return concatenate_videoclips(clips, method=\"compose\")\n",
    "\n",
    "\n",
    "def add_subtitles(video, segments):\n",
    "    composite_clips = [video]  # Start with the main video clip\n",
    "    for idx, segment in enumerate(segments):\n",
    "        text = segment.get(f'text_{idx+1}', '')  # Extract text\n",
    "        start_time = segment.get('start_time', 0)\n",
    "        end_time = segment.get('end_time', start_time + 5)  # Default duration 5 seconds\n",
    "\n",
    "        # Creating the subtitle clip\n",
    "        subtitle_clip = TextClip(\n",
    "            text, fontsize=60, color='white', font='Impact',\n",
    "            size=(video.size[0] * 0.8, None),  # Set width to 80% of the video width\n",
    "            method='caption', align='South', stroke_color='orange2', stroke_width=3.5,\n",
    "        )\n",
    "\n",
    "        # Set subtitle clip start and duration times\n",
    "        subtitle_clip = subtitle_clip.set_start(start_time).set_duration(end_time - start_time)\n",
    "\n",
    "        # Set position to center and make sure it maintains 10% margin\n",
    "        subtitle_clip = subtitle_clip.set_position(('right', 'bottom')) #horizontal,vertical\n",
    "\n",
    "        composite_clips.append(subtitle_clip)\n",
    "        print(\"subtitles added\")\n",
    "    \n",
    "    # Return a composite clip that includes the video and subtitles\n",
    "    return CompositeVideoClip(composite_clips)\n",
    "\n",
    "# Creating final video with ffmpeg\n",
    "def create_final_video(composite_video, audio, output_path):\n",
    "    temp_video_path = output_path.replace('.mp4', '_temp.mp4')\n",
    "    composite_video.write_videofile(temp_video_path, codec=\"libx264\", fps=24)\n",
    "    audio.write_audiofile(output_path.replace('.mp4', '_temp_audio.mp3'))\n",
    "    ffmpeg_command = [\n",
    "        'ffmpeg',\n",
    "        '-i', temp_video_path,\n",
    "        '-i', output_path.replace('.mp4', '_temp_audio.mp3'),\n",
    "        '-c:v', 'copy',\n",
    "        '-c:a', 'aac',\n",
    "        '-strict', 'experimental',\n",
    "        output_path\n",
    "    ]\n",
    "    subprocess.run(ffmpeg_command, check=True)\n",
    "\n",
    "\n",
    "temp_audio_dir = os.path.join(dir_name, 'temp_audio')\n",
    "os.makedirs(temp_audio_dir, exist_ok=True)\n",
    "\n",
    "image_files = [os.path.join(dir_name, f\"image_{i+1}.png\") for i in range(len(images_urls))]\n",
    "image_durations = [(item['end_time'] - item['start_time']) for item in segments]\n",
    "\n",
    "initial_video = create_video_clip(image_files)\n",
    "subtitled_video = add_subtitles(initial_video, segments)\n",
    "audio_clips = generate_audio_clips(segments, temp_audio_dir)\n",
    "final_video_path = os.path.join(dir_name, f\"{title}_final.mp4\")\n",
    "create_final_video(subtitled_video, audio_clips, final_video_path)\n",
    "\n",
    "print(f\"Final video with subtitles and audio saved to {final_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'video' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/p/Desktop/untitled folder 2/multiscript/2024-05-08_13-29-01\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Update this path\u001b[39;00m\n\u001b[1;32m     36\u001b[0m output_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_video.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m                \u001b[38;5;66;03m# Desired output file name\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mcreate_video_with_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mcreate_video_with_audio\u001b[0;34m(image_folder, output_file_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m clip \u001b[38;5;241m=\u001b[39m ImageSequenceClip(images, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Load the audio file\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#audio = AudioFileClip(os.path.join(image_folder, audio_file_name))\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# If the audio is longer than the video, you might want to cut it to match the video's duration\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#if audio.duration > clip.duration:\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m video \u001b[38;5;241m=\u001b[39m \u001b[43mvideo\u001b[49m\u001b[38;5;241m.\u001b[39mset_duration(clip\u001b[38;5;241m.\u001b[39mduration)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Write the result to a file (codec and bitrate can be adjusted according to your needs)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m video\u001b[38;5;241m.\u001b[39mwrite_videofile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_folder, output_file_name), codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibx264\u001b[39m\u001b[38;5;124m'\u001b[39m, bitrate\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8000k\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'video' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageSequenceClip, AudioFileClip\n",
    "import os\n",
    "\n",
    "def create_video_with_audio(image_folder, output_file_name):\n",
    "    # Find the only MP3 file in the specified folder\n",
    "    audio_files = [f for f in os.listdir(image_folder) if f.endswith('.mp3')]\n",
    "    \n",
    "    # Ensure that there's exactly one MP3 file\n",
    "    if len(audio_files) != 1:\n",
    "        raise ValueError(\"There must be exactly one MP3 file in the specified folder.\")\n",
    "    \n",
    "    audio_file_name = audio_files[0]\n",
    "    \n",
    "    # List images in the specified folder, sorted in ascending order\n",
    "    images = [os.path.join(image_folder, f) for f in sorted(os.listdir(image_folder)) if f.endswith('.png')]\n",
    "    \n",
    "    # Create a video clip from images, each image displayed for 6 seconds\n",
    "    clip = ImageSequenceClip(images, fps=1/6)\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio = AudioFileClip(os.path.join(image_folder, audio_file_name))\n",
    "    \n",
    "    # Set the audio of the clip as the loaded audio file\n",
    "    # Note: If audio duration is less than video, it will loop by default\n",
    "    video = clip.set_audio(audio)\n",
    "    \n",
    "    # If the audio is longer than the video, you might want to cut it to match the video's duration\n",
    "    if audio.duration > clip.duration:\n",
    "        video = video.set_duration(clip.duration)\n",
    "    \n",
    "    # Write the result to a file (codec and bitrate can be adjusted according to your needs)\n",
    "    video.write_videofile(os.path.join(image_folder, output_file_name), codec='libx264', bitrate='8000k')\n",
    "\n",
    "# Usage example:\n",
    "folder_path = '/path/to/your/images/and/audio'  # Update this path\n",
    "output_name = 'output_video.mp4'                # Desired output file name\n",
    "\n",
    "create_video_with_audio(folder_path, output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/p/Desktop/untitled folder 2/multiscript/2024-05-08_12-22-33/output_video.mp4.\n",
      "Moviepy - Writing video /Users/p/Desktop/untitled folder 2/multiscript/2024-05-08_12-22-33/output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/p/Desktop/untitled folder 2/multiscript/2024-05-08_12-22-33/output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "import os\n",
    "\n",
    "def create_video_from_images(image_folder, output_file_name):\n",
    "    # List all images in the specified folder, sorted in ascending order\n",
    "    images = [os.path.join(image_folder, f) for f in sorted(os.listdir(image_folder)) if f.endswith('.png')]\n",
    "    \n",
    "    # Create a video clip from images, each image displayed for 6 seconds\n",
    "    clip = ImageSequenceClip(images, fps=1/6)\n",
    "    \n",
    "    # Write the result to a file (codec and bitrate can be adjusted according to your needs)\n",
    "    clip.write_videofile(os.path.join(image_folder, output_file_name), codec='libx264', bitrate='8000k')\n",
    "\n",
    "# Usage example:\n",
    "folder_path = r'/Users/p/Desktop/untitled folder 2/multiscript/2024-05-08_12-22-33'  # Update this path\n",
    "output_name = 'output_video.mp4'      # Desired output file name\n",
    "\n",
    "create_video_from_images(folder_path, output_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
